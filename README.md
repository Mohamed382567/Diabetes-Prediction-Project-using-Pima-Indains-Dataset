# Diabetes Prediction Project using Pima Indains dataset

This project explores the process of building a machine learning model to predict the onset of diabetes based on diagnostic measurements. This is an **educational project** that demonstrates key machine learning concepts, and its core idea can be extended for more professional applications. It utilizes **professional data analysis techniques** throughout the workflow. The goal is to create a model that can effectively identify individuals at risk, prioritizing the detection of true diabetic cases.

Here's a simple overview of the project steps:

1.  **Data Loading and Initial Look:** We started by loading the diabetes dataset and getting a basic understanding of the data, including checking for missing values (especially non-physiological zeros in certain columns). Visualizations like the **Correlation Matrix** helped us understand relationships between different factors and diabetes risk.
2.  **Data Cleaning:** We addressed the non-physiological zero values in columns like Glucose, BloodPressure, etc., by treating them as missing data. We then used a sophisticated imputation technique (Iterative Imputer, or MICE) to fill these missing values based on the patterns in the rest of the data. We also handled cases of potentially negative insulin values by setting a physiological minimum.
3.  **Feature Engineering:** To help the model better understand the relationships in the data, we created several new features based on existing ones (e.g., ratios, interactions, log/sqrt transforms, and a critical glucose flag). We also categorized BMI into different groups.
4.  **Data Preparation for Modeling:**
    *   **Splitting Data:** We split the dataset into training (for teaching the model) and testing (for evaluating the model on unseen data) sets. It was important to split *before* scaling or SMOTE to prevent data leakage.
    *   **Scaling:** We standardized the numerical features so they all have a similar range, which is important for many models. The scaling was fitted *only* on the training data and applied to both training and testing data to avoid leakage.
    *   **Handling Imbalance (SMOTE):** Since there were likely fewer diabetic cases than non-diabetic ones, we used SMOTE on the *training data only* to create synthetic examples of the minority class. This helps the model learn to identify the diabetic cases better.
5.  **Model Training and Evaluation:** We trained several different machine learning models (like Random Forest, XGBoost, LightGBM, Logistic Regression, SVM) using the prepared training data. We evaluated their performance on the unseen test data using various metrics like AUC, Recall, Precision, and F1-Score. Key visualizations like the **Confusion Matrix** and **ROC Curve** were used to assess how well the models performed, especially in identifying diabetic cases.
6.  **Model Selection:** We chose the **Original Random Forest** model with a prediction threshold of **0.40** as our final model. This decision was primarily driven by the need to maximize **Recall** (correctly identifying as many diabetic cases as possible), even if it meant accepting a higher number of False Positives (healthy individuals incorrectly flagged as potentially diabetic). The **Feature Importance** plot helped us understand which patient characteristics the chosen model considered most important.
7.  **Understanding Trade-offs:** Selecting a low threshold (0.40) prioritized catching most diabetic individuals (high Recall) but led to flagging more healthy individuals incorrectly (more False Positives). The model also showed some moderate overfitting, meaning it performs slightly better on the training data than on new data. **We were compelled to accept these trade-offs and sacrifices, including the moderate overfitting, primarily due to the critical nature of the medical problem (where minimizing False Negatives is paramount) and the limitations imposed by the relatively small size of the available dataset.**
8.  **Prediction Function for New Data:** We created a `preprocess_input_data` function that takes raw data for new individuals, applies all the same cleaning and feature engineering steps that were done during training, and then uses the selected Random Forest model to provide a prediction (diabetic or not diabetic) and the associated probability.
9.  **Saving Preprocessing Tools:** To make the prediction function work reliably outside of this notebook, we saved the fitted **StandardScaler** and **IterativeImputer** models to files. The `preprocess_input_data` function is designed to load these saved tools internally when it runs.

In summary, this project followed a standard machine learning pipeline to build and select a diabetes prediction model, with a focus on correctly identifying diabetic cases. The final model and preprocessing pipeline are set up to take new patient data and provide a prediction, keeping in mind the trade-offs accepted during model selection.

*To try the prediction model instal the DiabetesPredictionFunctionFile file code and with it also install the random_forest_model / iterative_imputer file / standard_scaler file / training_columns file*

Happy to share the full notebook detailing all the steps [**https://colab.research.google.com/drive/1RMf_ucppTnTl-8B80lFwBfQ7ZVWVDaMq?usp=sharing**].

\#DataScience #MachineLearning #DataAnalysis #HealthcareAI #DiabetesPrediction #Python #RandomForest #AI #PortfolioProject
