{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Note: 1.Be sure that the 4 files are downloaded in the enviroment\n",
        "#       2.Run all the needed libraries\n",
        "#       3.Don't enter negative values or values less than 1 for (Glucose, BloodPressure, SkinThickness ,Insulin, BMI ) because it is not logically although the function can handle these values but to get better predictions"
      ],
      "metadata": {
        "id": "4gf9WhGfdCyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1MHnvfladu-o"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer, SimpleImputer\n",
        "from scipy.stats import zscore\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import roc_auc_score, f1_score, recall_score, precision_score, confusion_matrix, accuracy_score, roc_curve"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_input_data(file_path, model_path='random_forest_model.joblib', threshold=0.40):\n",
        "    \"\"\"\n",
        "    Preprocesses raw input data from a CSV file for diabetes prediction.\n",
        "    Loads the fitted scaler and imputer internally.\n",
        "    Performs imputation (for physiological zeros), feature engineering,\n",
        "    one-hot encoding, and scaling.\n",
        "    Makes a prediction using a provided model and threshold.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): The path to the CSV file containing the input data.\n",
        "                         Expected columns: 'Pregnancies', 'Glucose', 'BloodPressure',\n",
        "                                           'SkinThickness', 'Insulin', 'BMI', 'Age',\n",
        "                                           'DiabetesPedigreeFunction'.\n",
        "                         Values of 0 in Glucose, BloodPressure, SkinThickness,\n",
        "                                   Insulin, BMI are treated as missing and imputed.\n",
        "        model_path (str, optional): The path to the saved joblib file of the trained model.\n",
        "                                  Defaults to 'random_forest_model.joblib'.\n",
        "        threshold (float, optional): The prediction probability threshold (0 to 1).\n",
        "                                     Defaults to 0.40.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing:\n",
        "               - numpy.ndarray: The binary prediction (0 or 1) for each row.\n",
        "               - numpy.ndarray: The prediction probability (0 to 1) for the positive class (1) for each row.\n",
        "               Returns (None, None) if file loading, required file loading, or processing fails.\n",
        "    \"\"\"\n",
        "    # Load data from the CSV file\n",
        "    try:\n",
        "        input_data = pd.read_csv(file_path)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Input file not found at {file_path}\")\n",
        "        return None, None\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading input file {file_path}: {e}\")\n",
        "        return None, None\n",
        "\n",
        "    # Create a copy to avoid modifying the original input\n",
        "    processed_data = input_data.copy()\n",
        "\n",
        "    # --- Load the fitted scaler, imputer, and training columns internally ---\n",
        "    scaler_filename = 'standard_scaler.joblib'\n",
        "    imputer_filename = 'iterative_imputer.joblib'\n",
        "    training_columns_filename = 'training_columns.joblib'\n",
        "\n",
        "\n",
        "    try:\n",
        "        scaler = joblib.load(scaler_filename)\n",
        "        # print(f\"Scaler loaded successfully from '{scaler_filename}'\") # Keep print statements minimal in function\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Scaler file '{scaler_filename}' not found. Cannot preprocess data.\")\n",
        "        return None, None # Exit if scaler cannot be loaded\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading scaler: {e}\")\n",
        "        return None, None # Exit on other loading errors\n",
        "\n",
        "    try:\n",
        "        imputer = joblib.load(imputer_filename)\n",
        "        # print(f\"Imputer loaded successfully from '{imputer_filename}'\") # Keep print statements minimal\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Imputer file '{imputer_filename}' not found. Cannot preprocess data.\")\n",
        "        return None, None # Exit if imputer cannot be loaded\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading imputer: {e}\")\n",
        "        return None, None # Exit on other loading errors\n",
        "\n",
        "    try:\n",
        "        training_columns = joblib.load(training_columns_filename)\n",
        "        # print(f\"Training columns loaded successfully from '{training_columns_filename}'\") # Keep print statements minimal\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Training columns file '{training_columns_filename}' not found. Cannot preprocess data.\")\n",
        "        return None, None # Exit if training columns cannot be loaded\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading training columns: {e}\")\n",
        "        return None, None # Exit on other loading errors\n",
        "\n",
        "\n",
        "    # 1. Imputation (Handling non-physiological zeros)\n",
        "    # Define the target columns with non-physiological zero values used during training\n",
        "    # This list should be consistent with the training notebook\n",
        "    target_columns_impute = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
        "\n",
        "    # Create 'Is_Missing' flags before replacing zeros with NaN\n",
        "    for col in target_columns_impute:\n",
        "        flag_col_name = f'Is_{col}_Missing'\n",
        "        if col in processed_data.columns:\n",
        "             processed_data[flag_col_name] = (processed_data[col] == 0).astype(int)\n",
        "        else:\n",
        "             # Handle cases where an expected column is missing in input\n",
        "             print(f\"Warning: Imputation column '{col}' not found in input data. Adding '{flag_col_name}' flag with zeros.\")\n",
        "             processed_data[flag_col_name] = 0 # Add the missing flag column and set to 0\n",
        "\n",
        "    # Replace non-physiological zeros with np.nan *after* creating flags\n",
        "    for col in target_columns_impute:\n",
        "        if col in processed_data.columns:\n",
        "             # Only replace 0 if the column is in the target_columns_impute list\n",
        "             processed_data[col] = processed_data[col].replace(0, np.nan)\n",
        "\n",
        "\n",
        "    # Apply the loaded IterativeImputer (MICE)\n",
        "    # Identify numerical columns for imputation (all numerical columns present after flags are added)\n",
        "    # This list should ideally be derived from the training_columns list to ensure consistency\n",
        "    cols_to_impute_together_input = processed_data.select_dtypes(include=np.number).columns.tolist()\n",
        "\n",
        "    # Ensure we only try to impute columns that were imputed during training AND are in the input data\n",
        "    cols_to_impute_together_input = [col for col in cols_to_impute_together_input if col in imputer.feature_names_in_]\n",
        "\n",
        "\n",
        "    if len(cols_to_impute_together_input) > 0:\n",
        "         # Need to align columns before imputation if the input has a different order or subset\n",
        "         # A robust way is to create a subset of the input data with only the columns the imputer expects,\n",
        "         # impute, and then merge back.\n",
        "         input_subset_for_imputation = processed_data[imputer.feature_names_in_]\n",
        "\n",
        "         # Apply the loaded imputer to the data subset\n",
        "         imputed_data_array = imputer.transform(input_subset_for_imputation)\n",
        "\n",
        "         # Update the DataFrame with the imputed values for the imputed columns\n",
        "         # Need to handle the index correctly to ensure values align with the original rows\n",
        "         imputed_df_subset = pd.DataFrame(imputed_data_array, columns=imputer.feature_names_in_, index=processed_data.index)\n",
        "\n",
        "         # Update the original processed_data DataFrame with the imputed values\n",
        "         processed_data[imputer.feature_names_in_] = imputed_df_subset[imputer.feature_names_in_]\n",
        "    else:\n",
        "         print(\"Warning: No columns found in input data that were targeted for imputation during training.\")\n",
        "\n",
        "\n",
        "    # Correct negative insulin values (from imputation or input)\n",
        "    MIN_PHYSIOLOGICAL_INSULIN = 1.0\n",
        "    if 'Insulin' in processed_data.columns:\n",
        "        # Ensure clamping handles potential NaN values correctly\n",
        "        processed_data['Insulin'] = processed_data['Insulin'].apply(\n",
        "            lambda x: max(x, MIN_PHYSIOLOGICAL_INSULIN) if pd.notna(x) else x\n",
        "        )\n",
        "\n",
        "\n",
        "    # 2. Feature Engineering (Replicate exactly what was done in the notebook)\n",
        "    # Ensure EPSILON and GLUCOSE_CRITICAL_CUTOFF are defined or globally available\n",
        "    # Re-define them here to make the function self-contained\n",
        "    EPSILON = 1e-6\n",
        "    GLUCOSE_CRITICAL_CUTOFF = 126\n",
        "\n",
        "    # A. Log_DPF\n",
        "    if 'DiabetesPedigreeFunction' in processed_data.columns:\n",
        "        processed_data['Log_DPF'] = np.log(processed_data['DiabetesPedigreeFunction'].replace(0, EPSILON))\n",
        "    else:\n",
        "        # Add the column with a default value or based on imputation strategy for missing DPF\n",
        "        # Assuming if DPF is missing, log_DPF should reflect that. Imputing with mean/median of log_DPF from train might be better.\n",
        "        # For simplicity here, adding a placeholder if the original column is missing entirely.\n",
        "        print(\"Warning: 'DiabetesPedigreeFunction' column not found for Log_DPF. Adding column with default.\")\n",
        "        processed_data['Log_DPF'] = 0 # Consider a more robust imputation strategy if DPF can be missing\n",
        "\n",
        "\n",
        "    # B. Glucose_to_Insulin_Ratio\n",
        "    if 'Glucose' in processed_data.columns and 'Insulin' in processed_data.columns:\n",
        "         processed_data['Glucose_to_Insulin_Ratio'] = processed_data['Glucose'] / (processed_data['Insulin'] + EPSILON)\n",
        "    else:\n",
        "         print(\"Warning: 'Glucose' or 'Insulin' column not found for Glucose_to_Insulin_Ratio. Adding column with default.\")\n",
        "         processed_data['Glucose_to_Insulin_Ratio'] = 0 # Consider a more robust imputation strategy\n",
        "\n",
        "\n",
        "    # C. Age_BMI_Interaction\n",
        "    if 'Age' in processed_data.columns and 'BMI' in processed_data.columns:\n",
        "        processed_data['Age_BMI_Interaction'] = processed_data['Age'] * processed_data['BMI']\n",
        "    else:\n",
        "        print(\"Warning: 'Age' or 'BMI' column not found for Age_BMI_Interaction. Adding column with default.\")\n",
        "        processed_data['Age_BMI_Interaction'] = 0 # Consider a more robust imputation strategy\n",
        "\n",
        "\n",
        "    # D. Sqrt_Insulin\n",
        "    if 'Insulin' in processed_data.columns:\n",
        "        processed_data['Sqrt_Insulin'] = np.sqrt(processed_data['Insulin'].clip(lower=0)) # Ensure non-negative before sqrt\n",
        "    else:\n",
        "        print(\"Warning: 'Insulin' column not found for Sqrt_Insulin. Adding column with default.\")\n",
        "        processed_data['Sqrt_Insulin'] = 0 # Consider a more robust imputation strategy\n",
        "\n",
        "\n",
        "    # E. Sqrt_Pregnancies\n",
        "    if 'Pregnancies' in processed_data.columns:\n",
        "        processed_data['Sqrt_Pregnancies'] = np.sqrt(processed_data['Pregnancies'].clip(lower=0)) # Ensure non-negative\n",
        "    else:\n",
        "        print(\"Warning: 'Pregnancies' column not found for Sqrt_Pregnancies. Adding column with default.\")\n",
        "        processed_data['Sqrt_Pregnancies'] = 0 # Consider a more robust imputation strategy\n",
        "\n",
        "\n",
        "    # F. BP_Age_Index (Blood Pressure to Age Index)\n",
        "    if 'BloodPressure' in processed_data.columns and 'Age' in processed_data.columns:\n",
        "        processed_data['BP_Age_Index'] = processed_data['BloodPressure'] / (processed_data['Age'] + EPSILON)\n",
        "    else:\n",
        "        print(\"Warning: 'BloodPressure' or 'Age' column not found for BP_Age_Index. Adding column with default.\")\n",
        "        processed_data['BP_Age_Index'] = 0 # Consider a more robust imputation strategy\n",
        "\n",
        "\n",
        "    # G. Skin_BMI_Ratio (Skin Thickness to BMI Ratio)\n",
        "    if 'SkinThickness' in processed_data.columns and 'BMI' in processed_data.columns:\n",
        "        processed_data['Skin_BMI_Ratio'] = processed_data['SkinThickness'] / (processed_data['BMI'] + EPSILON)\n",
        "    else:\n",
        "        print(\"Warning: 'SkinThickness' or 'BMI' column not found for Skin_BMI_Ratio. Adding column with default.\")\n",
        "        processed_data['Skin_BMI_Ratio'] = 0 # Consider a more robust imputation strategy\n",
        "\n",
        "\n",
        "    # H. Is_Glucose_Critical (Critical Glucose Flag)\n",
        "    if 'Glucose' in processed_data.columns:\n",
        "        processed_data['Is_Glucose_Critical'] = (processed_data['Glucose'] >= GLUCOSE_CRITICAL_CUTOFF).astype(int)\n",
        "    else:\n",
        "        print(\"Warning: 'Glucose' column not found for Is_Glucose_Critical. Adding column with default.\")\n",
        "        processed_data['Is_Glucose_Critical'] = 0 # Add column with default value\n",
        "\n",
        "\n",
        "    # I. BMI_Category (requires the function definition)\n",
        "    def classify_bmi(bmi):\n",
        "        \"\"\"Classifies BMI into standard WHO categories.\"\"\"\n",
        "        if pd.isna(bmi): # Handle potential NaN from imputation\n",
        "            return 'Unknown' # Return a specific missing category for NaN BMI\n",
        "        elif bmi < 18.5:\n",
        "            return 'Underweight'\n",
        "        elif 18.5 <= bmi < 25:\n",
        "            return 'Normal'\n",
        "        elif 25 <= bmi < 30:\n",
        "            return 'Overweight'\n",
        "        elif 30 <= bmi < 35:\n",
        "            return 'Obese_Class_I'\n",
        "        elif 35 <= bmi < 40:\n",
        "            return 'Obese_Class_II'\n",
        "        else:\n",
        "            return 'Obese_Class_III'\n",
        "\n",
        "    if 'BMI' in processed_data.columns:\n",
        "         processed_data['BMI_Category'] = processed_data['BMI'].apply(classify_bmi)\n",
        "    else:\n",
        "         print(\"Warning: 'BMI' column not found for BMI_Category. Adding column with default.\")\n",
        "         processed_data['BMI_Category'] = 'Unknown' # Add column with default category\n",
        "\n",
        "\n",
        "    # 3. One-Hot Encode BMI_Category (Match training columns exactly)\n",
        "    # Create dummy variables for the BMI_Category column\n",
        "    processed_data = pd.get_dummies(processed_data, columns=['BMI_Category'], drop_first=False)\n",
        "\n",
        "\n",
        "    # Reindex processed_data to match the training columns, filling missing columns with 0\n",
        "    # This step is crucial for consistent feature sets between training and prediction.\n",
        "    # Ensure processed_data only contains columns that are in training_columns\n",
        "    # Drop any columns from processed_data that are NOT in training_columns (e.g., original columns if not dropped)\n",
        "    cols_to_keep = [col for col in processed_data.columns if col in training_columns]\n",
        "    processed_data = processed_data[cols_to_keep]\n",
        "\n",
        "    # Add missing columns (from training but not in input) and fill with 0\n",
        "    for col in training_columns:\n",
        "        if col not in processed_data.columns:\n",
        "            processed_data[col] = 0\n",
        "\n",
        "    # Ensure the order of columns matches the training data\n",
        "    processed_data = processed_data[training_columns]\n",
        "\n",
        "\n",
        "    # 4. Scaling (Apply the *fitted* scaler)\n",
        "    # Identify numerical columns for scaling, excluding binary flags and one-hot encoded columns\n",
        "    # This list should be derived consistently, ideally from the training_columns list\n",
        "    numerical_cols_for_scaling = [col for col in training_columns if not (col.startswith('Is_') or col.startswith('BMI_'))]\n",
        "\n",
        "    # Apply the fitted scaler transform\n",
        "    # Ensure that processed_data[numerical_cols_for_scaling] is a DataFrame before scaling\n",
        "    scaled_numerical_data = scaler.transform(processed_data[numerical_cols_for_scaling])\n",
        "\n",
        "    # Create a new DataFrame from scaled data and concatenate\n",
        "    scaled_numerical_df = pd.DataFrame(scaled_numerical_data, columns=numerical_cols_for_scaling, index=processed_data.index)\n",
        "\n",
        "    # Separate non-numerical columns (those that were not scaled)\n",
        "    non_numerical_cols = [col for col in processed_data.columns if col not in numerical_cols_for_scaling]\n",
        "    non_numerical_df = processed_data[non_numerical_cols]\n",
        "\n",
        "    # Concatenate scaled numerical and non-numerical columns\n",
        "    # Ensure column order matches training data by reindexing\n",
        "    processed_data_scaled = pd.concat([scaled_numerical_df, non_numerical_df], axis=1)\n",
        "    processed_data_scaled = processed_data_scaled[training_columns] # Reorder columns\n",
        "\n",
        "    # The processed_data_scaled DataFrame is now ready for prediction\n",
        "    X_processed = processed_data_scaled\n",
        "\n",
        "\n",
        "    # --- Make Prediction using the provided model path and threshold ---\n",
        "    try:\n",
        "        model = joblib.load(model_path)\n",
        "        # print(f\"Model loaded successfully from '{model_path}'\") # Keep print statements minimal\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: Model file '{model_path}' not found. Cannot make predictions.\")\n",
        "        return None, None\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {e}\")\n",
        "        return None, None\n",
        "\n",
        "\n",
        "    if not hasattr(model, 'predict_proba'):\n",
        "        print(\"Error: Loaded model does not have a predict_proba method for thresholding.\")\n",
        "        # If it's an SVM or similar, you might need decision_function\n",
        "        if hasattr(model, 'decision_function'):\n",
        "             print(\"Attempting to use decision_function for scoring...\")\n",
        "             prediction_scores = model.decision_function(X_processed)\n",
        "             # For binary classification, decision_function scores need conversion to a probability-like scale if possible,\n",
        "             # or you predict based on the sign. AUC can be calculated directly on decision_function scores.\n",
        "             # However, for a probability threshold, predict_proba is standard.\n",
        "             # Returning None, None as predict_proba is expected for thresholding.\n",
        "             return None, None # Exit if predict_proba is strictly required for the threshold\n",
        "\n",
        "        return None, None # Exit if neither predict_proba nor decision_function is available\n",
        "\n",
        "\n",
        "    # Get prediction probabilities\n",
        "    prediction_proba = model.predict_proba(X_processed)[:, 1]\n",
        "\n",
        "    # Apply the threshold to get the binary prediction\n",
        "    binary_prediction = (prediction_proba >= threshold).astype(int)\n",
        "\n",
        "    # Return both the binary prediction and the probability\n",
        "    return binary_prediction, prediction_proba"
      ],
      "metadata": {
        "id": "5AToYQQEMDLj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Usage (Requires a sample input file and the saved .joblib files)\n",
        "# Create a dummy CSV file for testing\n",
        "dummy_data = {\n",
        "    'Pregnancies': [2,5,0],\n",
        "    'Glucose': [100, 150,0],\n",
        "    'BloodPressure': [70, 80,0],\n",
        "    'SkinThickness': [25, 30,0],\n",
        "    'Insulin': [50, 0,0], # Include a zero for imputation test\n",
        "    'BMI': [30, 35,0],\n",
        "    'DiabetesPedigreeFunction': [0.5, 0.6,0.2],\n",
        "    'Age': [40, 50,22]\n",
        "}\n",
        "\n",
        "# --- Required input data to enter her in the dummy data ---\n",
        "\n",
        "dummy_df = pd.DataFrame(dummy_data)\n",
        "dummy_csv_path = 'sample_input_data.csv'\n",
        "dummy_df.to_csv(dummy_csv_path, index=False)\n",
        "\n",
        "# Use the preprocess_input_data function with the dummy CSV\n",
        "# The function now loads the scaler, imputer, and model internally\n",
        "predictions, probabilities = preprocess_input_data(dummy_csv_path, model_path='random_forest_model.joblib', threshold=0.40)\n",
        "\n",
        "# Display the results\n",
        "if predictions is not None and probabilities is not None:\n",
        "    print(f\"\\nPredictions for data from '{dummy_csv_path}':\")\n",
        "    print(f\"Binary Predictions (Threshold=0.40): {predictions}\")\n",
        "    print(f\"Prediction Probabilities (Diabetic): {probabilities}\")\n",
        "else:\n",
        "    print(\"\\nPreprocessing or prediction failed.\")\n",
        "\n",
        "\n",
        "# Test with the logically healthy and sick individuals\n",
        "# Assuming combined_csv_path and the CSV file exists from the previous example\n",
        "if 'combined_csv_path' in locals() and combined_csv_path:\n",
        "    print(f\"\\nTesting with combined sample data from '{combined_csv_path}':\")\n",
        "    predictions_combined, probabilities_combined = preprocess_input_data(combined_csv_path, model_path='random_forest_model.joblib', threshold=0.40)\n",
        "\n",
        "    if predictions_combined is not None and probabilities_combined is not None:\n",
        "        print(f\"Binary Predictions (Threshold=0.40): {predictions_combined}\")\n",
        "        print(f\"Prediction Probabilities (Diabetic): {probabilities_combined}\")\n",
        "    else:\n",
        "        print(\"Preprocessing or prediction for combined data failed.\")\n",
        "else:\n",
        "    print(\"\\nCombined sample data CSV path not found. Skipping test with combined data.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "941f1eb6-569d-436b-c73d-6af1d186b453",
        "id": "7cMrJq0vaS9N"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predictions for data from 'sample_input_data.csv':\n",
            "Binary Predictions (Threshold=0.40): [0 1 1]\n",
            "Prediction Probabilities (Diabetic): [0.21554671 0.7885325  0.41635334]\n",
            "\n",
            "Combined sample data CSV path not found. Skipping test with combined data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2-endWSNbsmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "026713b9",
        "outputId": "27b5937d-5721-4e19-baef-1271aacf514c"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define data for a logically healthy individual\n",
        "healthy_data = {\n",
        "    'Pregnancies': 0,\n",
        "    'Glucose': 80,\n",
        "    'BloodPressure': 60,\n",
        "    'SkinThickness': 20,\n",
        "    'Insulin': 50,\n",
        "    'BMI': 22,\n",
        "    'DiabetesPedigreeFunction': 0.1,\n",
        "    'Age': 25\n",
        "}\n",
        "\n",
        "# Define data for a logically sick individual\n",
        "sick_data = {\n",
        "    'Pregnancies': 5,\n",
        "    'Glucose': 180,\n",
        "    'BloodPressure': 90,\n",
        "    'SkinThickness': 40,\n",
        "    'Insulin': 250,\n",
        "    'BMI': 40,\n",
        "    'DiabetesPedigreeFunction': 0.8,\n",
        "    'Age': 55\n",
        "}\n",
        "\n",
        "# Combine the data for both individuals into a list\n",
        "combined_data = [healthy_data, sick_data]\n",
        "\n",
        "# Create a pandas DataFrame from the combined data\n",
        "combined_df = pd.DataFrame(combined_data)\n",
        "\n",
        "print(\"Created a DataFrame with one healthy and one sick individual:\")\n",
        "display(combined_df)\n",
        "\n",
        "# You can now use this 'combined_df' with your preprocessing and prediction logic\n",
        "# For example, you could save it to a CSV and use the preprocess_input_data function:\n",
        "combined_csv_path = 'combined_sample_data.csv'\n",
        "combined_df.to_csv(combined_csv_path, index=False)\n",
        "\n",
        "# Call preprocess_input_data and get the predictions and probabilities\n",
        "predictions_combined, probabilities_combined = preprocess_input_data(combined_csv_path)\n",
        "\n",
        "print(\"\\nPredictions Combined Data:\")\n",
        "if predictions_combined is not None and probabilities_combined is not None:\n",
        "    print(f\"Binary Predictions (Threshold=0.40): {predictions_combined}\")\n",
        "    print(f\"Prediction Probabilities (Diabetic): {probabilities_combined}\")\n",
        "else:\n",
        "    print(\"Preprocessing or prediction for combined data failed.\")\n",
        "\n",
        "loaded_model = joblib.load('random_forest_model.joblib')\n",
        "# The preprocess_input_data function already returns the predictions and probabilities,\n",
        "# so we don't need to call predict and predict_proba on the loaded model here.\n",
        "# If you want to test with the loaded model directly, you would need the processed DataFrame.\n",
        "# However, the preprocess_input_data function is designed to handle the entire process.\n",
        "\n",
        "# If you specifically wanted the processed DataFrame, you would modify preprocess_input_data\n",
        "# to return the processed_data_scaled DataFrame as well.\n",
        "# For now, we will rely on the output of preprocess_input_data as intended.\n",
        "\n",
        "# print(f\"\\nPredictions: {predictions}\") # Remove these lines as they were using the incorrect input\n",
        "# print(f\"Probabilities: {probabilities}\") # Remove these lines"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created a DataFrame with one healthy and one sick individual:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin  BMI  \\\n",
              "0            0       80             60             20       50   22   \n",
              "1            5      180             90             40      250   40   \n",
              "\n",
              "   DiabetesPedigreeFunction  Age  \n",
              "0                       0.1   25  \n",
              "1                       0.8   55  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ff18f02e-e93a-4f45-a4d5-ba74e9b27e35\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>60</td>\n",
              "      <td>20</td>\n",
              "      <td>50</td>\n",
              "      <td>22</td>\n",
              "      <td>0.1</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>180</td>\n",
              "      <td>90</td>\n",
              "      <td>40</td>\n",
              "      <td>250</td>\n",
              "      <td>40</td>\n",
              "      <td>0.8</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff18f02e-e93a-4f45-a4d5-ba74e9b27e35')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ff18f02e-e93a-4f45-a4d5-ba74e9b27e35 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ff18f02e-e93a-4f45-a4d5-ba74e9b27e35');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ed9b3e05-5451-43ea-81c6-e8ce1dba56cc\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ed9b3e05-5451-43ea-81c6-e8ce1dba56cc')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ed9b3e05-5451-43ea-81c6-e8ce1dba56cc button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_ba69b7cf-21d0-4cd8-ab55-dbb357a5e02e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('combined_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ba69b7cf-21d0-4cd8-ab55-dbb357a5e02e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('combined_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "combined_df",
              "summary": "{\n  \"name\": \"combined_df\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"Pregnancies\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          5,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Glucose\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 70,\n        \"min\": 80,\n        \"max\": 180,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          180,\n          80\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BloodPressure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21,\n        \"min\": 60,\n        \"max\": 90,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          90,\n          60\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SkinThickness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 20,\n        \"max\": 40,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          40,\n          20\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Insulin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 141,\n        \"min\": 50,\n        \"max\": 250,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          250,\n          50\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BMI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12,\n        \"min\": 22,\n        \"max\": 40,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          40,\n          22\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DiabetesPedigreeFunction\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4949747468305833,\n        \"min\": 0.1,\n        \"max\": 0.8,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.8,\n          0.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 21,\n        \"min\": 25,\n        \"max\": 55,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          55,\n          25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predictions Combined Data:\n",
            "Binary Predictions (Threshold=0.40): [0 1]\n",
            "Prediction Probabilities (Diabetic): [0.02392885 0.84824353]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# And here we wanted to be more sure that also the model can predicect data that is very logicaly than the the first is healthy and the second is diabetec\n",
        "# And the model acutly predicted right\n",
        "# 0 means healthy and 1 means unhealthy"
      ],
      "metadata": {
        "id": "jvk3USij9FCs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}